{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting timezonefinder\n",
      "  Using cached timezonefinder-5.2.0-py36.py37.py38-none-any.whl (43.0 MB)\n",
      "Requirement already satisfied: numpy>=1.16 in /usr/lib/python3/dist-packages (from timezonefinder) (1.17.4)\n",
      "Installing collected packages: timezonefinder\n",
      "Successfully installed timezonefinder-5.2.0\n"
     ]
    }
   ],
   "source": [
    "import sys  \n",
    "!{sys.executable} -m pip install --user timezonefinder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import time\n",
    "import datetime\n",
    "import os\n",
    "from timezonefinder import TimezoneFinder\n",
    "from pytz import timezone\n",
    "import pytz\n",
    "import glob\n",
    "import pickle\n",
    "import math\n",
    "import itertools\n",
    "\n",
    "tf = TimezoneFinder(in_memory=True)\n",
    "\n",
    "utc = pytz.utc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function declarations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Example script that scrapes data from the IEM ASOS download service\n",
    "\"\"\"\n",
    "# Python 2 and 3: alternative 4\n",
    "try:\n",
    "    from urllib.request import urlopen\n",
    "except ImportError:\n",
    "    from urllib2 import urlopen\n",
    "\n",
    "# Number of attempts to download data\n",
    "MAX_ATTEMPTS = 6\n",
    "# HTTPS here can be problematic for installs that don't have Lets Encrypt CA\n",
    "SERVICE = \"http://mesonet.agron.iastate.edu/cgi-bin/request/asos.py?\"\n",
    "\n",
    "output_dir = os.path.relpath('US_METAR_data')\n",
    "if not os.path.isdir(output_dir):\n",
    "    os.mkdir(output_dir)\n",
    "    \n",
    "def download_data(uri):\n",
    "    \"\"\"Fetch the data from the IEM\n",
    "    The IEM download service has some protections in place to keep the number\n",
    "    of inbound requests in check.  This function implements an exponential\n",
    "    backoff to keep individual downloads from erroring.\n",
    "    Args:\n",
    "      uri (string): URL to fetch\n",
    "    Returns:\n",
    "      string data\n",
    "    \"\"\"\n",
    "    attempt = 0\n",
    "    while attempt < MAX_ATTEMPTS:\n",
    "        try:\n",
    "            data = urlopen(uri, timeout=300).read().decode('utf-8')\n",
    "            if data is not None and not data.startswith('ERROR'):\n",
    "                return data\n",
    "        except Exception as exp:\n",
    "            print(\"download_data(%s) failed with %s\" % (uri, exp))\n",
    "            time.sleep(5)\n",
    "        attempt += 1\n",
    "\n",
    "    print(\"Exhausted attempts to download, returning empty data\")\n",
    "    return \"\"\n",
    "\n",
    "\n",
    "def get_stations_from_filelist(filename):\n",
    "    \"\"\"Build a listing of stations from a simple file listing the stations.\n",
    "    The file should simply have one station per line.\n",
    "    \"\"\"\n",
    "    stations = []\n",
    "    for line in open(filename):\n",
    "        stations.append(line.strip())\n",
    "    return stations\n",
    "\n",
    "\n",
    "def get_stations_from_networks():\n",
    "    \"\"\"Build a station list by using a bunch of IEM networks.\"\"\"\n",
    "    stations = []\n",
    "    US_states = \"\"\"AK AL AR AZ CA CO CT DE FL GA HI IA ID IL IN KS KY LA MA MD ME\n",
    "     MI MN MO MS MT NC ND NE NH NJ NM NV NY OH OK OR PA RI SC SD TN TX UT VA VT\n",
    "     WA WI WV WY\"\"\"\n",
    "    # IEM quirk to have Iowa AWOS sites in its own labeled network\n",
    "    networks = ['AWOS']\n",
    "    for state in US_states.split():\n",
    "        networks.append(\"%s_ASOS\" % (state,))\n",
    "\n",
    "    for network in networks:\n",
    "        # Get metadata\n",
    "        uri = (\"https://mesonet.agron.iastate.edu/\"\n",
    "               \"geojson/network/%s.geojson\") % (network,)\n",
    "        data = urlopen(uri)\n",
    "        jdict = json.load(data)\n",
    "        for site in jdict['features']:\n",
    "            stations.append(site['properties']['sid'])\n",
    "    return stations\n",
    "\n",
    "\n",
    "def offset(target):\n",
    "    \"\"\"\n",
    "    returns a location's time zone offset from UTC.\n",
    "    \"\"\"\n",
    "    today = datetime.datetime.now()\n",
    "    tz_target = timezone(tf.certain_timezone_at(lat=target['lat'], lng=target['lng']))\n",
    "    # ATTENTION: tz_target could be None! handle error case\n",
    "\n",
    "    # today_target = tz_target.localize(today)\n",
    "    # today_utc = utc.localize(today)\n",
    "    # offset = today_utc - today_target\n",
    "    offset = tz_target.utcoffset(today)\n",
    "\n",
    "    # if `today` is in summer time while the target isn't, you may want to substract the DST\n",
    "    offset -= tz_target.dst(today)\n",
    "    return offset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use this to only pull in more data when you need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading: KBHM\n",
      "Downloading: PANC\n",
      "Downloading: KPHX\n",
      "Downloading: KLIT\n",
      "Downloading: KLAX\n",
      "Downloading: KDEN\n",
      "Downloading: KBDL\n",
      "Downloading: KILG\n",
      "Downloading: KMIA\n",
      "Downloading: KATL\n",
      "Downloading: PHNL\n",
      "Downloading: KBOI\n",
      "Downloading: KORD\n",
      "Downloading: KIND\n",
      "Downloading: KDSM\n",
      "Downloading: KICT\n",
      "Downloading: KCVG\n",
      "Downloading: KMSY\n",
      "Downloading: KPWM\n",
      "Downloading: KBWI\n",
      "Downloading: KBOS\n",
      "Downloading: KDTW\n",
      "Downloading: KMSP\n",
      "Downloading: KJAN\n",
      "Downloading: KSTL\n",
      "Downloading: KBZN\n",
      "Downloading: KOMA\n",
      "Downloading: KLAS\n",
      "Downloading: KMHT\n",
      "Downloading: KEWR\n",
      "Downloading: KABQ\n",
      "Downloading: KJFK\n",
      "Downloading: KCLT\n",
      "Downloading: KFAR\n",
      "Downloading: KCLE\n",
      "Downloading: KOKC\n",
      "Downloading: KPDX\n",
      "Downloading: KPHL\n",
      "Downloading: KPVD\n",
      "Downloading: KCHS\n",
      "Downloading: KFSD\n",
      "Downloading: KBNA\n",
      "Downloading: KDFW\n",
      "Downloading: KSLC\n",
      "Downloading: KBTV\n",
      "Downloading: KDCA\n",
      "Downloading: KSEA\n",
      "Downloading: KCRW\n",
      "Downloading: KMKE\n",
      "Downloading: KJAC\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Our main method\"\"\"\n",
    "# timestamps in UTC to request data for\n",
    "startts = datetime.datetime(2015, 1, 1)\n",
    "# endts = datetime.datetime(2018, 12, 31)\n",
    "endts = datetime.datetime.now().date()\n",
    "\n",
    "service = SERVICE + \"data=all&tz=Etc/UTC&format=comma&latlon=yes&\"\n",
    "\n",
    "service += startts.strftime('year1=%Y&month1=%m&day1=%d&')\n",
    "service += endts.strftime('year2=%Y&month2=%m&day2=%d&')\n",
    "\n",
    "# Two examples of how to specify a list of stations\n",
    "# stations = get_stations_from_networks()\n",
    "# stations = get_stations_from_filelist(\"mystations.txt\")\n",
    "\n",
    "\"\"\"\n",
    "KBHM = Birmingham, Alabama\n",
    "PANC = Anchorage, Alaska\n",
    "KPHX = Pheonix, Arizona\n",
    "KLIT = Little Rock, Arkansas\n",
    "KLAX = Los Angeles, California\n",
    "KDEN = Denver, Colorado\n",
    "KBDL = Hartford, Connecticut\n",
    "KILG = Wilmington, Delaware\n",
    "KMIA = Miami, Florida\n",
    "KATL = Atlanta, Georgia\n",
    "PHNL = Honolulu, Hawaii\n",
    "KBOI = Boise, Idaho\n",
    "KORD = Chicago, Illinois\n",
    "KIND = Indianapolis, Indiana\n",
    "KDSM = Des Moines, Iowa\n",
    "KICT = Wichita, Kansas\n",
    "KCVG = Cincinnati, Kentucky\n",
    "KMSY = New Orleans, Louisiana\n",
    "KPWM = Portland, Maine\n",
    "KBWI = Baltimore, Maryland\n",
    "KBOS = Boston, Massacheusetts\n",
    "KDTW = Detroit, Michigan\n",
    "KMSP = Minneapolis, Minnesota\n",
    "KJAN = Jackson, Mississippi\n",
    "KSTL = St. Louis, Missouri\n",
    "KBZN = Bozeman, Montana\n",
    "KOMA = Omaha, Nebraska\n",
    "KLAS = Las Vegas, Nevada\n",
    "KMHT = New Hampshire\n",
    "KEWR = Newark, New Jersey\n",
    "KABQ = Albuquerque, New Mexico\n",
    "KJFK = New York, New York\n",
    "KCLT = Charlotte, North Carolina\n",
    "KFAR = Fargo, North Dakota\n",
    "KCLE = Cleveland, Ohio\n",
    "KOKC = Oklahoma City, Oklahoma\n",
    "KPDX = Portland, Oregon\n",
    "KPHL = Philadelphia, Pennsylvania\n",
    "KPVD = Providence, Rhode Island\n",
    "KCHS = Charleston, South Carolina\n",
    "KFSD = Sioux Falls, South Dakota\n",
    "KBNA = Nashville, Tennessee\n",
    "KDFW = Dallas-Fort Worth, Texas\n",
    "KSLC = Salt Lake City, Utah\n",
    "KBTV = Burlington, Vermont\n",
    "KDCA = Washington D.C, Virginia\n",
    "KSEA = Seattle, Washington\n",
    "KCRW = Charleston, West Virginia\n",
    "KMKE = Milwaukee, Wisconsin\n",
    "KJAC = Jackson, Wyoming\n",
    "\"\"\"\n",
    "\n",
    "stations = ['KBHM','PANC','KPHX','KLIT','KLAX','KDEN','KBDL','KILG','KMIA','KATL','PHNL','KBOI','KORD', 'KIND',\n",
    "            'KDSM', 'KICT', 'KCVG', 'KMSY', 'KPWM', 'KBWI', 'KBOS', 'KDTW', 'KMSP', 'KJAN', 'KSTL', 'KBZN', \n",
    "            'KOMA', 'KLAS', 'KMHT', 'KEWR', 'KABQ', 'KJFK', 'KCLT', 'KFAR', 'KCLE', 'KOKC', 'KPDX', 'KPHL', \n",
    "            'KPVD', 'KCHS', 'KFSD', 'KBNA', 'KDFW', 'KSLC', 'KBTV', 'KDCA', 'KSEA', 'KCRW', 'KMKE', 'KJAC']\n",
    "\n",
    "for station in stations:\n",
    "    uri = '%s&station=%s' % (service, station)\n",
    "    print('Downloading: %s' % (station, ))\n",
    "    data = download_data(uri)\n",
    "    outfn = os.path.join(output_dir, '%s_%s_%s.txt' % (station, startts.strftime(\"%Y%m%d%H%M\"),\n",
    "                              endts.strftime(\"%Y%m%d%H%M\")))\n",
    "    out = open(outfn, 'w')\n",
    "    out.write(data)\n",
    "    out.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing\n",
    "- Converting Sky Condition categories into quantifiable numbers\n",
    "- Converting datetime string to datetime format\n",
    "- Adding UTC offset based on location, and **filtering data between 8am - 5pm**\n",
    "- Getting rid of cloud values that are above 20k feet. Because you can just go under them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_yssy = pd.read_csv('output/YSSY_201501010000_201909020000.txt', skiprows=5)\n",
    "# df = df_yssy[['valid','station','lat','lon','skyc1','skyc2','skyc3', 'skyc4','skyl1','skyl2','skyl3', 'skyl4','metar']]\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py:3145: DtypeWarning: Columns (10,12) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>valid</th>\n",
       "      <th>station</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>skyc1</th>\n",
       "      <th>skyc2</th>\n",
       "      <th>skyc3</th>\n",
       "      <th>skyc4</th>\n",
       "      <th>skyl1</th>\n",
       "      <th>skyl2</th>\n",
       "      <th>skyl3</th>\n",
       "      <th>skyl4</th>\n",
       "      <th>metar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-01-01 00:53</td>\n",
       "      <td>LAX</td>\n",
       "      <td>33.9382</td>\n",
       "      <td>-118.3865</td>\n",
       "      <td>FEW</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "      <td>5000.00</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "      <td>KLAX 010053Z 32010KT 10SM FEW050 12/M11 A3001 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-01-01 01:53</td>\n",
       "      <td>LAX</td>\n",
       "      <td>33.9382</td>\n",
       "      <td>-118.3865</td>\n",
       "      <td>CLR</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "      <td>KLAX 010153Z 33006G14KT 10SM CLR 11/M09 A3003 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-01-01 02:53</td>\n",
       "      <td>LAX</td>\n",
       "      <td>33.9382</td>\n",
       "      <td>-118.3865</td>\n",
       "      <td>CLR</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "      <td>KLAX 010253Z 34007KT 10SM CLR 10/M09 A3004 RMK...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-01-01 03:53</td>\n",
       "      <td>LAX</td>\n",
       "      <td>33.9382</td>\n",
       "      <td>-118.3865</td>\n",
       "      <td>CLR</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "      <td>KLAX 010353Z 35007KT 10SM CLR 10/M10 A3005 RMK...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-01-01 04:53</td>\n",
       "      <td>LAX</td>\n",
       "      <td>33.9382</td>\n",
       "      <td>-118.3865</td>\n",
       "      <td>CLR</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "      <td>KLAX 010453Z 00000KT 10SM CLR 09/M10 A3006 RMK...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              valid station      lat       lon skyc1 skyc2 skyc3 skyc4  \\\n",
       "0  2015-01-01 00:53     LAX  33.9382 -118.3865   FEW     M     M     M   \n",
       "1  2015-01-01 01:53     LAX  33.9382 -118.3865   CLR     M     M     M   \n",
       "2  2015-01-01 02:53     LAX  33.9382 -118.3865   CLR     M     M     M   \n",
       "3  2015-01-01 03:53     LAX  33.9382 -118.3865   CLR     M     M     M   \n",
       "4  2015-01-01 04:53     LAX  33.9382 -118.3865   CLR     M     M     M   \n",
       "\n",
       "     skyl1 skyl2 skyl3 skyl4  \\\n",
       "0  5000.00     M     M     M   \n",
       "1        M     M     M     M   \n",
       "2        M     M     M     M   \n",
       "3        M     M     M     M   \n",
       "4        M     M     M     M   \n",
       "\n",
       "                                               metar  \n",
       "0  KLAX 010053Z 32010KT 10SM FEW050 12/M11 A3001 ...  \n",
       "1  KLAX 010153Z 33006G14KT 10SM CLR 11/M09 A3003 ...  \n",
       "2  KLAX 010253Z 34007KT 10SM CLR 10/M09 A3004 RMK...  \n",
       "3  KLAX 010353Z 35007KT 10SM CLR 10/M10 A3005 RMK...  \n",
       "4  KLAX 010453Z 00000KT 10SM CLR 09/M10 A3006 RMK...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('US_METAR_data/KLAX_201501010000_202107240000.txt', skiprows=5)\n",
    "df = df[['valid','station','lat','lon','skyc1','skyc2','skyc3', 'skyc4','skyl1','skyl2','skyl3', 'skyl4','metar']]\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py:3337: DtypeWarning: Columns (10,12) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  if (await self.run_code(code, result,  async_=asy)):\n",
      "/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py:3337: DtypeWarning: Columns (12) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  if (await self.run_code(code, result,  async_=asy)):\n",
      "/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py:3337: DtypeWarning: Columns (10) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  if (await self.run_code(code, result,  async_=asy)):\n"
     ]
    }
   ],
   "source": [
    "filenames = glob.glob('US_METAR_data/*201501010000_202107240000.txt')\n",
    "df_list = [pd.read_csv(filename, skiprows=5) for filename in filenames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "concat_df = pd.DataFrame()\n",
    "\n",
    "for df in df_list:\n",
    "    # Some clean up\n",
    "    df = df[['valid','station','lat','lon','skyc1','skyc2','skyc3', 'skyc4','skyl1','skyl2','skyl3', 'skyl4','metar']]\n",
    "    if df.empty:\n",
    "        raise Exception('Empty Dataframe')\n",
    "    df = df.replace('M', np.NaN)\n",
    "    df.dropna(subset=['metar'], inplace=True) # Omits rows without METAR information\n",
    "    # if skyc1 is 'CLR' ensure that skyl1 is 12k ft. (find reference for this)\n",
    "    df.loc[df.skyc1 == 'CLR', 'skyl1'] = 12000\n",
    "\n",
    "    # Converting Sky Condition categories into quantifiable numbers\n",
    "    weather_dict = {'FEW' : 1.5,  # Few\n",
    "                    'SCT' : 3.5,  # Scattered\n",
    "                    'BKN' : 6,    # Broken\n",
    "                    'OVC' : 8,    # Overcast\n",
    "                    'SKC' : 0,    # Sky Clear\n",
    "                    'NCD' : 0,    # No Cloud Detected\n",
    "                    'NSC' : 0,    # No Significant Clouds\n",
    "                    'CLR' : 0,    # Clear: seems like a US term\n",
    "                    'CAVOK' : 0}  # Celing and Visibility OK\n",
    "                   #'M' : np.NaN}\n",
    "    df['skyc1'] = df['skyc1'].map(weather_dict)\n",
    "    df['skyc2'] = df['skyc2'].map(weather_dict)\n",
    "    df['skyc3'] = df['skyc3'].map(weather_dict)\n",
    "    df['skyc4'] = df['skyc4'].map(weather_dict)\n",
    "    df = df.astype({'skyl1': 'float32', 'skyl2': 'float32', 'skyl3': 'float32', 'skyl4': 'float32'})\n",
    "   \n",
    "\n",
    "    # Adding UTC offset based on location, and filtering data between 8am - 5pm\n",
    "    df.valid = pd.to_datetime(df.valid, infer_datetime_format=True)\n",
    "    location = dict({'lat':df['lat'][0], 'lng':df['lon'][0]})\n",
    "    timedelta = offset(location)\n",
    "    df.valid = df.valid + timedelta\n",
    "    df = df[df.valid.dt.strftime('%H:%M:%S').between('08:00:00','17:00:00')]\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        # If 'CAVOK' is the Metar, report 0 okta at 5k ft and 0.5 Okta up to 10ft\n",
    "        # This is a very rough heuristic, research on METAR more before solidifying this\n",
    "        if 'CAVOK' in df.at[index,'metar'].split(' '):\n",
    "            if row.isnull()['skyc1']:\n",
    "                df.at[index,'skyc1'] = 0\n",
    "                df.at[index,'skyl1'] = 5000\n",
    "            if row.isnull()['skyc2']:\n",
    "                df.at[index,'skyc2'] = 0.5\n",
    "                df.at[index,'skyl2'] = 10000\n",
    "        # Omitting readings above 20k ft\n",
    "        if row['skyl3'] > 20000:\n",
    "            df.at[index,'skyc3'] = np.NaN\n",
    "            df.at[index,'skyl3'] = np.NaN\n",
    "        if row['skyl4'] > 20000:\n",
    "            df.at[index,'skyc4'] = np.NaN\n",
    "            df.at[index,'skyl4'] = np.NaN\n",
    "\n",
    "    # Averaging cloud cover information for all the categories - dumb method\n",
    "    # NOTE: its better to create 'avg_cloud' here instead of after the groupby because\n",
    "    # all the NaN entries are averaged better. The averages don't match up in the final df because\n",
    "    # different sky categories have different amounts of NaNs\n",
    "    df['avg_cloud'] = df[['skyc1', 'skyc2','skyc3','skyc4']].mean(axis=1)\n",
    "    # if avg_cloud for a location == NaN, use the previous date's value at the same location\n",
    "    for i in range(1, len(df)):\n",
    "        if i == 0: continue\n",
    "        if df.iloc[i].isnull()[13]:\n",
    "            df.iat[i,13] = df.iat[i-1,13]\n",
    "    \n",
    "    concat_df = pd.concat([concat_df, df], sort=False)\n",
    "    \n",
    "## Compressing the dataframe - from hours into days of years - Then years into a single year\n",
    "concat_df = concat_df.groupby([concat_df.valid.dt.strftime(\"%m/%d\"), concat_df.station]).mean()\n",
    "# concat_df['avg_cloud'] = concat_df[['skyc1', 'skyc2','skyc3','skyc4']].mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>skyc1</th>\n",
       "      <th>skyc2</th>\n",
       "      <th>skyc3</th>\n",
       "      <th>skyc4</th>\n",
       "      <th>skyl1</th>\n",
       "      <th>skyl2</th>\n",
       "      <th>skyl3</th>\n",
       "      <th>skyl4</th>\n",
       "      <th>avg_cloud</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>valid</th>\n",
       "      <th>station</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">01/01</th>\n",
       "      <th>ABQ</th>\n",
       "      <td>35.0419</td>\n",
       "      <td>-106.6155</td>\n",
       "      <td>2.568293</td>\n",
       "      <td>5.023207</td>\n",
       "      <td>7.064626</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6443.572266</td>\n",
       "      <td>5275.472656</td>\n",
       "      <td>5916.993164</td>\n",
       "      <td>14000.0</td>\n",
       "      <td>3.319888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ATL</th>\n",
       "      <td>33.6301</td>\n",
       "      <td>-84.4418</td>\n",
       "      <td>4.205607</td>\n",
       "      <td>6.340000</td>\n",
       "      <td>6.888889</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3889.860596</td>\n",
       "      <td>6125.756348</td>\n",
       "      <td>8683.901367</td>\n",
       "      <td>13750.0</td>\n",
       "      <td>5.120699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BDL</th>\n",
       "      <td>41.9381</td>\n",
       "      <td>-72.6825</td>\n",
       "      <td>1.939539</td>\n",
       "      <td>5.680851</td>\n",
       "      <td>5.347826</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8713.620117</td>\n",
       "      <td>8003.191406</td>\n",
       "      <td>7108.695801</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.130277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BHM</th>\n",
       "      <td>33.5655</td>\n",
       "      <td>-86.7449</td>\n",
       "      <td>2.685668</td>\n",
       "      <td>6.625616</td>\n",
       "      <td>7.802469</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7050.569824</td>\n",
       "      <td>6021.083984</td>\n",
       "      <td>6507.357910</td>\n",
       "      <td>14000.0</td>\n",
       "      <td>3.247213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BNA</th>\n",
       "      <td>36.1189</td>\n",
       "      <td>-86.6892</td>\n",
       "      <td>3.841338</td>\n",
       "      <td>6.008696</td>\n",
       "      <td>6.840426</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6071.336426</td>\n",
       "      <td>5639.886719</td>\n",
       "      <td>5055.212891</td>\n",
       "      <td>20000.0</td>\n",
       "      <td>3.858672</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   lat       lon     skyc1     skyc2     skyc3  skyc4  \\\n",
       "valid station                                                           \n",
       "01/01 ABQ      35.0419 -106.6155  2.568293  5.023207  7.064626    6.0   \n",
       "      ATL      33.6301  -84.4418  4.205607  6.340000  6.888889    8.0   \n",
       "      BDL      41.9381  -72.6825  1.939539  5.680851  5.347826    NaN   \n",
       "      BHM      33.5655  -86.7449  2.685668  6.625616  7.802469    6.0   \n",
       "      BNA      36.1189  -86.6892  3.841338  6.008696  6.840426    6.0   \n",
       "\n",
       "                     skyl1        skyl2        skyl3    skyl4  avg_cloud  \n",
       "valid station                                                             \n",
       "01/01 ABQ      6443.572266  5275.472656  5916.993164  14000.0   3.319888  \n",
       "      ATL      3889.860596  6125.756348  8683.901367  13750.0   5.120699  \n",
       "      BDL      8713.620117  8003.191406  7108.695801      NaN   2.130277  \n",
       "      BHM      7050.569824  6021.083984  6507.357910  14000.0   3.247213  \n",
       "      BNA      6071.336426  5639.886719  5055.212891  20000.0   3.858672  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concat_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'output/US_weather_7yr_avg'\n",
    "# Open the file for writing\n",
    "with open(file_name,'wb') as my_file_obj:\n",
    "    pickle.dump(concat_df,my_file_obj)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
